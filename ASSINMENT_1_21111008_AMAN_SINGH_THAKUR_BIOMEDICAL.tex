\documentclass[12pt]{article}

\usepackage{graphicx}
\graphicspath{{img/}}
\usepackage{hyperref}
\hypersetup{colorlinks=true, citecolor=blue , linkcolor=blue,urlcolor=blue}

\title{NATIONAL INSTITUTE OF TECHNOLOGY\\
(NIT)RAIPUR (C.G.)}
\author {SESSION 2021-22}
\date{}
\begin{document}
\maketitle
\begin{figure}[h]
\centering
\includegraphics[scale=0.5]{NIT.png}
\end{figure}
\author {------------------ ASSINMENT-1 ON  {5 MEDICAL DEVICES} ----------------}\\


\author{GUIDANCE BY \>  \>\> \>\> \>  \>\> \>\> \>\>  \>\>\>\>  \>\> \>\>\>  \>\> \>\> \>  \>\> \>\>   \>\> \>\>  SUBMITTED BY }\\


\author{DR.SAURABH GUPTA\>  \>\> \>\> \>  \>\> \>\>\>\>\>  \>\> \>\>\>  \>\> \>\> \>  \>\> AMAN SINGH THAKUR }\\

\author{ ASSISTANT PROFESSOR\>  \>\> \>  \> \>   \>\> \>\> \> \>\> \> \>\> \>  ROLL NO.:--- 21111008 }\\
\author{BIOMEDICAL DEPARTMENT\>  \>\> \>\> \>  \>\> \>\> \>\>   \>\> BRANCHE:--BIOMEDICAL  }\\
\author{.\>   \>\> \>\> \>  \>\> \>\> \>\> \>\> \>\> \>  \>\> \>\> \>\>\>\> \>\> \>\>  \>\> \>\> \>\> \>\>\> \>\> \>   \>\> \>\> \>\> \>\>\> \>\> \>    \>\> \>\> \>\> \>\> \>\> \>  \>\> \>\> \>\>  \>\> ENGINEERING }
\clearpage
\tableofcontents
\clearpage
\section{ PULSE OXIMETER}

Pulse oximetry is a noninvasive method for monitoring a person's oxygen saturation.Peripheral oxygen saturation readings are typically within 2\% accuracy of the more accurate reading of arterial oxygen saturation from arterial blood gas analysis.The two are correlated well enough that the safe, convenient, noninvasive, inexpensive pulse oximetry method is valuable for measuring oxygen saturation in clinical use.The most common approach is transmissive pulse oximetry.It measures the changing absorbance at each of the wavelengths, allowing it to determine the absorbances due to the pulsing arterial blood alone, excluding venous blood, skin, bone, muscle, fat, and nail polish.Reflectance pulse oximetry is a less common alternative to transmissive pulse oximetry.Vasodilation and pooling of venous blood in the head due to compromised venous return to the heart can cause a combination of arterial and venous pulsations in the forehead region and lead to spurious SpO2 results.[FIGURE\ref{fig_PUL}]
\begin{figure}[h]
\centering
\includegraphics[scale=2]{PUL.png}
\caption{Tetherless pulse oximetry
,Purpose::Monitoring a person's oxygen saturation}
\label{fig_PUL}
\end{figure}
\subsection{Medical uses}
A pulse oximeter is a medical device that indirectly monitors the oxygen saturation of a patient's blood and changes in blood volume in the skin, producing a photoplethysmogram that may be further processed into other measurements.
The pulse oximeter may be incorporated into a multiparameter patient monitor.
Portable, battery-operated pulse oximeters are also available for transport or home blood-oxygen monitoring.

\subsection{Advantages}

Pulse oximetry is useful in any setting where a patient's oxygenation is unstable, including intensive care, operating, recovery, emergency and hospital ward settings, pilots in unpressurized aircraft, for assessment of any patient's oxygenation, and determining the effectiveness of or need for supplemental oxygen.
Although a pulse oximeter is used to monitor oxygenation, it cannot determine the metabolism of oxygen, or the amount of oxygen being used by a patient.
The use of a pulse oximeter to detect hypoventilation is impaired with the use of supplemental oxygen, as it is only when patients breathe room air that abnormalities in respiratory function can be detected reliably with its use.
Because of their simplicity of use and the ability to provide continuous and immediate oxygen saturation values, pulse oximeters are of critical importance in emergency medicine and are also very useful for patients with respiratory or cardiac problems, especially COPD, or for diagnosis of some sleep disorders such as apnea and hypopnea.
Some portable pulse oximeters employ software that charts a patient's blood oxygen and pulse, serving as a reminder to check blood oxygen levels.
Connectivity advancements have made it possible for patients to have their blood oxygen saturation continuously monitored without a cabled connection to a hospital monitor, without sacrificing the flow of patient data back to bedside monitors and centralized patient surveillance systems.
For patients with COVID-19, pulse oximetry helps with early detection of silent hypoxia, in which the patients still look and feel comfortable, but their SpO2 is perilously low. [FIGURE\ref{fig_PUL1}]

\begin{figure}[h]
\centering
\includegraphics[scale=0.7]{PUL1.jpg}
\caption{A pulse oximeter probe applied to a person's finger}
\label{fig_PUL1}
\end{figure}
\subsection{Limitations}
Pulse oximetry solely measures hemoglobin saturation, not ventilation and is not a complete measure of respiratory sufficiency.
To ensure accuracy, the sensor should return a steady pulse and/or pulse waveform.
Pulse oximetry technologies differ in their abilities to provide accurate data during conditions of motion and low perfusion.
Some home pulse oximeters have low sampling rates which can significantly underestimate dips in blood oxygen levels.
The accuracy of pulse oximetry deteriorates considerably for readings below 80\%. Pulse oximetry also is not a complete measure of circulatory oxygen sufficiency.
Since pulse oximetry measures only the percentage of bound hemoglobin, a falsely high or falsely low reading will occur when hemoglobin binds to something other than oxygen: Hemoglobin has a higher affinity to carbon monoxide than it does to oxygen, and a high reading may occur despite the patient's actually being hypoxemic.
Methemoglobinemia characteristically causes pulse oximetry readings in the mid-80s. COPD may cause false readings.
\subsection{Equipment}
In addition to pulse oximeters for professional use, many inexpensive "Consumer" models are available.
Opinions vary about the reliability of consumer oximeters; a typical comment is "The research data on home monitors has been mixed, but they tend to be accurate within a few percentage points".
Some smart watches with activity tracking incorporate an oximeter function.
Pulse oximeters used for diagnosis of conditions such as COVID-19 should be Class IIB medical grade oximeters.
Class IIB oximeters can be used on patients of all skin colors, low pigmentation and in the presence of motion.
Mobile apps Mobile app pulse oximeters use the flashlight and the camera of the phone, instead of infrared light used in conventional pulse oximeters.
So even though pulse oximeters aren't perfect, they're still much more accurate compared to the smartphone apps pulse oximeters.

\subsection{Mechanism}
A blood-oxygen monitor displays the percentage of blood that is loaded with oxygen. More specifically, it measures what percentage of hemoglobin, the protein in blood that carries oxygen, is loaded. Acceptable normal SaO2 ranges for patients without pulmonary pathology are from 95 to 99 percent.[citation needed] For a person breathing room air at or near sea level, an estimate of arterial pO2 can be made from the blood-oxygen monitor "saturation of peripheral oxygen" (SpO2) readin

\subsection{Mode of operation}
Absorption of light at these wavelengths differs significantly between blood loaded with oxygen and blood lacking oxygen.
Oxygenated hemoglobin absorbs more infrared light and allows more red light to pass through.
Deoxygenated hemoglobin allows more infrared light to pass through and absorbs more red light.
The LEDs sequence through their cycle of one on, then the other, then both off about thirty times per second which allows the photodiode to respond to the red and infrared light separately and also adjust for the ambient light baseline.
The amount of light that is transmitted is measured, and separate normalized signals are produced for each wavelength.
By subtracting the minimum transmitted light from the transmitted light in each wavelength, the effects of other tissues are corrected for, generating a continuous signal for pulsatile arterial blood.
The ratio of the red light measurement to the infrared light measurement is then calculated by the processor, and this ratio is then converted to SpO2 by the processor via a lookup table based on the Beer-Lambert law.

\subsection{History}
Nihon Kohden manufactured the first pulse oximeter, Ear Oximeter OLV-5100, and Susumu Nakajima, a surgeon, and his associates first tested the device in patients, reporting it in 1975.
Nihon Kohden suspended the development of pulse oximetry and didn't apply for a basic patent of pulse oximetry except in Japan.
Early studies of pulse oximetry performance during subject motion made clear the vulnerabilities of conventional pulse oximetry technologies to motion artifact.
Published papers have compared signal extraction technology to other pulse oximetry technologies and have demonstrated consistently favorable results for signal extraction technology.
Signal extraction technology pulse oximetry performance has also been shown to translate into helping clinicians improve patient outcomes.
In 2020, a follow-up retrospective study at the same institution showed that over ten years of using pulse oximetry with signal extraction technology, coupled with a patient surveillance system, there were zero patient deaths and no patients were harmed by opioid-induced respiratory depression while continuous monitoring was in use.
High-resolution pulse oximetry has been developed for in-home sleep apnea screening and testing in patients for whom it is impractical to perform polysomnography.
\clearpage
\section{AIR PURIFYING RESPIRATOR}
Air-purifying respirators are respirators that draw in the surrounding air and purify it before it is breathed.
Air-purifying respirators are used against particulates, gases, and vapors that are at atmospheric concentrations less than immediately dangerous to life and health.
Air-purifying respirators may use one or both of two kinds of filtration: mechanical filters retain particulate matter, while chemical cartridges remove gases, volatile organic compounds, and other vapors.
Air-purifying respirators may come in many forms: filtering facepiece respirators consist solely of a disposable mechanical filter; elastomeric respirators are reusable but have replaceable filters attached to the mask; and powered air-purifying respirators have a battery-powered blower that moves the airflow through the filters.
According to the NIOSH Respirator Selection Logic, air-purifying respirators are recommended for concentrations of hazardous particulates or gases that are greater than the relevant occupational exposure limit but less than the immediately dangerous to life or health level and the manufacturer's maximum use concentration, subject to the respirator having a sufficient assigned protection factor.
For substances hazardous to the eyes, a respirator equipped with a full facepiece, helmet, or hood is recommended.
Air-purifying respirators are not effective during firefighting, in oxygen-deficient atmosphere, or in an unknown atmosphere; in these situations a self-contained breathing apparatus is recommended instead.[FIGURE \ref{fig_ARR1}]
\begin{figure}[h]
\centering
\includegraphics[scale=0.5]{ARR1.jpg}
\caption{"How  Men may Breathe Safely in a Covid Atmosphere"}
\label{fig_ARR1}
\end{figure}
\subsection{Types of filtration}
\subsubsection{Mechanical filter}
Mechanical filter respirators retain particulate matter such as dust created during woodworking or metal processing, when contaminated air is passed through the filter material.
Since the filters cannot be cleaned and reused and have a limited lifespan, cost and disposability are key factors.
In the United States, the National Institute for Occupational Safety and Health defines the categories of particulate filters according to their NIOSH air filtration rating.
The most common of these are the N95 respirator, which filters at least 95\% of airborne particles but is not resistant to oil.
Other categories filter 99\% or 99.97\% of particles, or have varying degrees of resistance to oil.
In the European Union, European standard EN 143 defines the 'P' classes of particle filters that can be attached to a face mask, while European standard EN 149 defines classes of "Filtering half masks" or "Filtering facepieces", usually called FFP masks.
According to 3M, respirators made according to the following standards from other countries are equivalent to U.S. N95 or European FFP2 respirators include the Chinese KN95, Australian / New Zealand P2, Korean 1st Class also referred to as KF94, and Japanese DS..

\subsubsection{Chemical filter}
Chemical cartridge respirators use a cartridge to remove gases, volatile organic compounds, and other vapors from breathing air by adsorption, absorption, or chemisorption.
A typical organic vapor respirator cartridge is a metal or plastic case containing from 25 to 40 grams of sorption media such as activated charcoal or certain resins.
The service life of the cartridge varies based, among other variables, on the carbon weight and molecular weight of the vapor and the cartridge media, the concentration of vapor in the atmosphere, the relative humidity of the atmosphere, and the breathing rate of the respirator wearer.
When filter cartridges become saturated or particulate accumulation within them begins to restrict air flow, they must be changed.
If the concentration of harmful gases is immediately dangerous to life or health, in workplaces covered by the Occupational Safety and Health Act the US Occupational Safety and Health Administration specifies the use of air-supplied respirators except when intended solely for escape during emergencies.
NIOSH also discourages their use under such conditions.[FIGURE \ref{fig_ARR}]

\begin{figure}[h]
\centering
\includegraphics[scale=3]{ARR.png}
\caption{"How a Man may Breathe Safely in a Poisonous Atmosphere", an apparatus providing oxygen while using caustic soda to absorb carbon dioxide, 1909}
\label{fig_ARR}
\end{figure}
\subsection{Form factors}
These are typically simple, light, single-piece, half-face masks and employ the first three mechanical filter mechanisms in the list above to remove particulates from the air stream.
His nose and mouth are covered by a gray rubber respirator with bright pink filters.
Main article: Elastomeric respirator Elastomeric respirators are reusable because the facepiece is cleaned and reused, but the filter cartridges are discarded and replaced when they become unsuitable for further use.
Powered air-purifying respirators Main article: Powered air-purifying respirator Powered air-purifying respirators have a battery-powered blower that moves the airflow through the filters.
The units consist of a powered fan which forces incoming air through one or more filters to the user for breathing.
The filter type must be matched to the contaminants that need to be removed.
These must have their filter elements replaced more often than a particulate filter.

\subsubsection{History}
Some were made of rubberized fabric, and still others of impregnated fabric, but in most cases a tank of compressed air or a reservoir of air under slight pressure was carried by the wearer to supply the necessary breathing air.
In some devices certain means were provided for the adsorption of carbon dioxide in exhaled air and the rebreathing of the same air many times; in other cases valves allowed exhalation of used air.
The mask worked by capturing moisture and warmth in exhaled air in a grid of fine metal wires.
Following Haslett, a long string of patents were issued for air purifying devices, including patents for the use of cotton fibers as a filtering medium, for charcoal and lime absorption of poisonous vapors, and for improvements on the eyepiece and eyepiece assembly.
Irish physicist John Tyndall took Stenhouse's mask, added a filter of cotton wool saturated with lime, glycerin, and charcoal, and in 1871 invented a 'fireman's respirator', a hood that filtered smoke and gas from air, which he exhibited at a meeting of the Royal Society in London in 1874.
' German Bernhard Loeb patented several inventions to 'purify foul or vitiated air,' and counted the Brooklyn Fire Department among his customers.
In the 1970s, the Bureau of Mines and NIOSH developed standards for single-use respirators, and the first N95 respirator was developed by 3M and approved in 1972.
\clearpage
\section{X-ray GENERATOR}
An X-ray generator is a device that produces X-rays. Together with an X-ray detector, it is commonly used in a variety of applications including medicine, X-ray fluorescence, electronic assembly inspection, and measurement of material thickness in manufacturing operations. In medical applications, X-ray generators are used by radiographers to acquire x-ray images of the internal structures (e.g., bones) of living organisms, and also in sterilization.
\subsection{Structure}
An X-ray generator generally contains an X-ray tube to produce the X-rays.
Possibly, radioisotopes can also be used to generate X-rays.
An X-ray tube is a simple vacuum tube that contains a cathode, which directs a stream of electrons into a vacuum, and an anode, which collects the electrons and is made of tungsten to evacuate the heat generated by the collision.
When the electrons collide with the target, about 1\% of the resulting energy is emitted as X-rays, with the remaining 99\% released as heat.
Due to the high energy of the electrons that reach relativistic speeds the target is usually made of tungsten even if other material can be used particularly in XRF applications.
An X-ray generator also needs to contain a cooling system to cool the anode; many X-ray generators use water or oil recirculating systems.

\subsection{Medical imaging}
Medical imaging In medical imaging applications, an X-ray machine has a control console that is used by a radiologic technologist to select X-ray techniques suitable for the specific exam, a power supply that creates and produces the desired kVp, mA for the X-ray tube, and the X-ray tube itself.[FIGURE \ref{fig_XR}]
\begin{figure}[h]
\centering
\includegraphics[scale=0.8]{XR.jpg}
\caption{A radiology room table. The X-ray housing is turned by 90° for a chest radiograph}
\label{fig_XR}
\end{figure}

\subsection{History}
The discovery of X-rays came from experimenting with Crookes tubes, an early experimental electrical discharge tube invented by English physicist William Crookes around 1869-1875.
In 1895, Wilhelm Röntgen discovered X-rays emanating from Crookes tubes and the many uses for X-rays were immediately apparent.
One of the first X-ray photographs was made of the hand of Röntgen's wife.
On January 18, 1896 an X-ray machine was formally displayed by Henry Louis Smith.
In the 1940s and 1950s, X-ray machines were used in stores to help sell footwear.
As the harmful effects of X-ray radiation were properly considered, they finally fell out of use.
Together with Robert J. Van de Graaff, John G. Trump developed one of the first million-volt X-ray generators.


\subsection{Overview}
An X-ray imaging system consists of a generator control console where the operator selects desired techniques to obtain a quality readable image(kVp, mA and exposure time), an x-ray generator which controls the x-ray tube current, x-ray tube kilovoltage and x-ray emitting exposure time, an X-ray tube that converts the kilovoltage and mA into actual x-rays and an image detection system which can be either a film (analog technology) or a digital capture system and a PACS.
\subsection{Applications}
Radiography is generally used for fast, highly penetrating images, and is usually used in areas with a high bone content but can also be used to look for tumors such as with mammography imaging.
Some forms of radiography include: orthopantomogram - a panoramic x-ray of the jaw showing all the teeth at once mammography - x-rays of breast tissue tomography - x-ray imaging in sections In fluoroscopy, imaging of the digestive tract is done with the help of a radiocontrast agent such as barium sulfate, which is opaque to X-rays.
Barium enema - a procedure used to examine problems of the colon and lower gastrointestinal tract barium swallow - similar to a barium enema, but used to examine the upper gastrointestinal tract biopsy - the removal of tissue for examination Pain Management - used to visually see and guide needles for administering/injecting pain medications, steroids or pain blocking medications throughout the spinal region.
Orthopedic procedures - used to guide placement and removal of bone structure reinforcement plates, rods and fastening hardware used to aide the healing process and alignment of bone structures healing properly together.
X-rays are highly penetrating, ionizing radiation, therefore X-ray machines are used to take pictures of dense tissues such as bones and teeth.[FIGURE \ref{fig_XR1}]
\begin{figure}[h]
\centering
\includegraphics[scale=1.2]{XR1.jpg}
\caption{Acquisition of projectional radiography, with an X-ray generator and a detector.}
\label{fig_XR1}
\end{figure}
The main parts of an X-ray Baggage Inspection System are the generator used to generate x-rays, the detector to detect radiation after passing through the baggage, signal processor unit to process the incoming signal from the detector, and a conveyor system for moving baggage into the system.
Portable pulsed X-ray Battery Powered X-ray Generator used in Security as shown in the figure provides EOD responders safer analysis of any possible target hazard.
\clearpage
\section{MICROSCOPE}
A microscope; examine, inspect') is a laboratory instrument used to examine objects that are too small to be seen by the naked eye.
Microscopy is the science of investigating small objects and structures using a microscope.
Microscopic means being invisible to the eye unless aided by a microscope.
There are many types of microscopes, and they may be grouped in different ways.
One way is to describe the method an instrument uses to interact with a sample and produce images, either by sending a beam of light or electrons through a sample in its optical path, by detecting photon emissions from a sample, or by scanning across and a short distance from the surface of a sample using a probe.
The most common microscope is the optical microscope, which uses lenses to refract visible light that passed through a thinly sectioned sample to produce an observable image.
Other major types of microscopes are the fluorescence microscope, electron microscope and various types of scanning probe microscopes.[FIGURE \ref{fig_MIC}]
\begin{figure}[h]
\centering
\includegraphics[scale=0.5]{MIC.jpg}
\caption{Microscope}
\label{fig_MIC}
\end{figure}

\subsection{History}
Although objects resembling lenses date back 4,000 years and there are Greek accounts of the optical properties of water-filled spheres followed by many centuries of writings on optics, the earliest known use of simple microscopes dates back to the widespread use of lenses in eyeglasses in the 13th century.
The earliest known examples of compound microscopes, which combine an objective lens near the specimen with an eyepiece to view a real image, appeared in Europe around 1620.
The inventor is unknown, even though many claims have been made over the years.
Several revolve around the spectacle-making centers in the Netherlands, including claims it was invented in 1590 by Zacharias Janssen or Zacharias' father, Hans Martens, or both, claims it was invented by their neighbor and rival spectacle maker, Hans Lippershey, and claims it was invented by expatriate Cornelis Drebbel, who was noted to have a version in London in 1619.
Galileo Galilei seems to have found after 1610 that he could close focus his telescope to view small objects and, after seeing a compound microscope built by Drebbel exhibited in Rome in 1624, built his own improved version.
Giovanni Faber coined the name microscope for the compound microscope Galileo submitted to the Accademia dei Lincei in 1625.

\subsubsection{Rise of modern light microscopes}
A significant contribution came from Antonie van Leeuwenhoek who achieved up to 300 times magnification using a simple single lens microscope.
Van Leeuwenhoek re-discovered red blood cells and spermatozoa, and helped popularise the use of microscopes to view biological ultrastructure.
The performance of a light microscope depends on the quality and correct use of the condensor lens system to focus light on the specimen and the objective lens to capture the light from the specimen and form an image.
Early instruments were limited until this principle was fully appreciated and developed from the late 19th to very early 20th century, and until electric lamps were available as light sources.
In 1893 August Köhler developed a key principle of sample illumination, Köhler illumination, which is central to achieving the theoretical limits of resolution for the light microscope.
This method of sample illumination produces even lighting and overcomes the limited contrast and resolution imposed by early techniques of sample illumination.
Further developments in sample illumination came from the discovery of phase contrast by Frits Zernike in 1953, and differential interference contrast illumination by Georges Nomarski in 1955; both of which allow imaging of unstained, transparent samples.

\subsubsection{Electron microscopes}
In the early 20th century a significant alternative to the light microscope was developed, an instrument that uses a beam of electrons rather than light to generate an image.
The German physicist, Ernst Ruska, working with electrical engineer Max Knoll, developed the first prototype electron microscope in 1931, a transmission electron microscope.
The transmission electron microscope works on similar principles to an optical microscope but uses electrons in the place of light and electromagnets in the place of glass lenses.
Development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope by Max Knoll.
Transmission electron microscopes became popular following the Second World War.
Ernst Ruska, working at Siemens, developed the first commercial transmission electron microscope and, in the 1950s, major scientific conferences on electron microscopy started being held.
In 1965, the first commercial scanning electron microscope was developed by Professor Sir Charles Oatley and his postgraduate student Gary Stewart, and marketed by the Cambridge Instrument Company as the "Stereoscan".

\subsubsection{Scanning probe microscopes}
From 1981 to 1983 Gerd Binnig and Heinrich Rohrer worked at IBM in Zurich, Switzerland to study the quantum tunnelling phenomenon.
They created a practical instrument, a scanning probe microscope from quantum tunnelling theory, that read very small forces exchanged between a probe and the surface of a sample.
The probe approaches the surface so closely that electrons can flow continuously between probe and sample, making a current from surface to probe.
The microscope was not initially well received due to the complex nature of the underlying theoretical explanations.
In 1984 Jerry Tersoff and D.R. Hamann, while at AT\&T's Bell Laboratories in Murray Hill, New Jersey began publishing articles that tied theory to the experimental results obtained by the instrument.
This was closely followed in 1985 with functioning commercial instruments, and in 1986 with Gerd Binnig, Quate, and Gerber's invention of the atomic force microscope, then Binnig's and Rohrer's Nobel Prize in Physics for the SPM. New types of scanning probe microscope have continued to be developed as the ability to machine ultra-fine probes and tips has advanced.

\subsubsection{Fluorescence microscopes}
The most recent developments in light microscope largely centre on the rise of fluorescence microscopy in biology.
During the last decades of the 20th century, particularly in the post-genomic era, many techniques for fluorescent staining of cellular structures were developed.
The main groups of techniques involve targeted chemical staining of particular cell structures, for example, the chemical compound DAPI to label DNA, use of antibodies conjugated to fluorescent reporters, see immunofluorescence, and fluorescent proteins, such as green fluorescent protein.
These techniques use these different fluorophores for analysis of cell structure at a molecular level in both live and fixed samples.
The rise of fluorescence microscopy drove the development of a major modern microscope design, the confocal microscope.
The principle was patented in 1957 by Marvin Minsky, although laser technology limited practical application of the technique.
It was not until 1978 when Thomas and Christoph Cremer developed the first practical confocal laser scanning microscope and the technique rapidly gained popularity through the 1980s.[FIGURE \ref{fig_MIC2}]
\begin{figure}[h]
\centering
\includegraphics[scale=0.7]{MIC2.jpg}
\caption{Fluorescence microscope with the filter cube turret above the objective lenses, coupled with a camera.}
\label{fig_MIC2}
\end{figure}

\subsubsection{Super resolution microscopes}
Much current research on optical microscope techniques is focused on development of superresolution analysis of fluorescently labelled samples.
Structured illumination can improve resolution by around two to four times and techniques like stimulated emission depletion microscopy are approaching the resolution of electron microscopes.
This occurs because the diffraction limit is occurred from light or excitation, which makes the resolution must be doubled to become super saturated.

\subsubsection{X-ray microscopes}
 X-ray microscope X-ray microscopes are instruments that use electromagnetic radiation usually in the soft X-ray band to image objects.
Technological advances in X-ray lens optics in the early 1970s made the instrument a viable imaging choice.
They are often used in tomography to produce three dimensional images of objects, including biological materials that have not been chemically fixed.
Currently research is being done to improve optics for hard X-rays which have greater penetrating power.

\subsection{Types}
Microscopes can be classified based on whether they analyze the sample via a scanning point or analyze the sample all at once.
Wide field optical microscopes and transmission electron microscopes both use the theory of lenses in order to magnify the image generated by the passage of a wave transmitted through the sample, or reflected by the sample.
Resolution in these microscopes is limited by the wavelength of the radiation used to image the sample, where shorter wavelengths allow for a higher resolution.
Scanning optical and electron microscopes, like the confocal microscope and scanning electron microscope, use lenses to focus a spot of light or electrons onto the sample then analyze the signals generated by the beam interacting with the sample.
These microscopes have the same resolution limit as wide field optical, probe, and electron microscopes.
Scanning probe microscopes also analyze a single point in the sample and then scan the probe over a rectangular sample region to build up an image.
As these microscopes do not use electromagnetic or electron radiation for imaging they are not subject to the same resolution limit as the optical and electron microscopes described above.


\subsubsection{Optical}
The most common type of microscope is the optical microscope.
Optical microscopes have refractive glass, to focus light on the eye or on to another light detector.
Typical magnification of a light microscope, assuming visible range light, is up to 1250x with a theoretical resolution limit of around 0.250 micrometres or 250 nanometres.
The use of shorter wavelengths of light, such as ultraviolet, is one way to improve the spatial resolution of the optical microscope, as are devices such as the near-field scanning optical microscope.
Phase-contrast microscopy is an optical microscopy illumination technique in which small phase shifts in the light passing through a transparent specimen are converted into amplitude or contrast changes in the image.
The traditional optical microscope has more recently evolved into the digital microscope.
Digital microscopy with very low light levels to avoid damage to vulnerable biological samples is available using sensitive photon-counting digital cameras.

\subsubsection{Electron}
The two major types of electron microscopes are transmission electron microscopes and scanning electron microscopes.
In a TEM the electrons pass through the sample, analogous to basic optical microscopy.
This requires careful sample preparation, since electrons are scattered strongly by most materials.
The samples must also be very thin in order for the electrons to pass through it.
In contrast, the SEM has raster coils to scan the surface of bulk objects with a fine electron beam.
The specimen do not necessarily need to be sectioned, but coating with a nanometric metal or carbon layer may be needed for nonconductive samples.
SEM allows fast surface imaging of samples, possibly in thin water vapor to prevent drying.


\subsubsection{Scanning probe}
The different types of scanning probe microscopes arise from the many different types of interactions that occur when a small probe is scanned over and interacts with a specimen.
The three most common types of scanning probe microscopes are atomic force microscopes, near-field scanning optical microscopes, and scanning tunneling microscopes.
An atomic force microscope has a fine probe, usually of silicon or silicon nitride, attached to a cantilever; the probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are measured and mapped.
A near-field scanning optical microscope is similar to an AFM but its probe consists of a light source in an optical fiber covered with a tip that has usually an aperture for the light to pass through.
The microscope can capture either transmitted or reflected light to measure very localized optical properties of the surface, commonly of a biological specimen.
Scanning tunneling microscopes have a metal tip with a single apical atom; the tip is attached to a tube through which a current flows.
The tip is scanned over the surface of a conductive sample until a tunneling current flows; the current is kept constant by computer movement of the tip and an image is formed by the recorded movements of the tip.
\clearpage
\section{TATTOO REMOVAL}
Tattoo removal has been performed with various tools since the start of tattooing.
While tattoos are generally considered permanent, it is now possible to remove them with treatments, fully or partially.
The "Standard modality for tattoo removal" is the non-invasive removal of tattoo pigments using Q-switched lasers.
Different types of Q-switched lasers are used to target different colors of tattoo ink depending on the specific light absorption spectra of the tattoo pigments.
For a couple of decades before that, continuous-wave lasers were used as medical lasers for tattoo removal.
Continuous-wave lasers used a high energy beam that ablated the target area and destroyed surrounding tissue structures as well as tattoo ink.
Before the development of laser tattoo removal methods, common techniques included dermabrasion, TCA, salabrasion, cryosurgery, and excision, which is sometimes still used along with skin grafts for larger tattoos.[FIGURE \ref{fig_TAT}]
\begin{figure}[h]
\centering
\includegraphics[scale=2]{TAT.png}
\caption{"Example of a tattoo removal laser"}
\label{fig_TAT}
\end{figure}
\subsection{Motives}
A poll conducted in January 2012 by Harris Interactive reported that 1 in 7 of the 21\% of American adults who have a tattoo regret getting one.
The poll did not report the reasons for these regrets, but a poll that was done four years prior reported that the most common reasons were "Too young when I got the tattoo", "It's permanent" and "I'm marked for life", and "I just don't like it".
An earlier poll showed that 19\% of Britons with tattoos suffered regret, as did 11\% of Italians with tattoos.
Surveys of tattoo removal patients were done in 1996 and 2006 and provided more insight.
Angelina Jolie, Eva Longoria, Marc Anthony, and Denise Richards are some of the celebrities who have had this kind of tattoo removed.
The choice to get a tattoo that is later regretted is related to the end-of-history illusion in which teenagers and adults of all ages know that their tastes have changed regularly over the years before the current moment but believe that their tastes will somehow not continue to grow and mature in the future.
As a result, they wrongly believe that any tattoo that appeals to them today will always appeal to them in the future.

\subsection{Removal by replacement}
Some wearers decide to cover an unwanted tattoo with a new tattoo.
An artfully done cover-up may render the old tattoo completely invisible, though this will depend largely on the size, style, colors and techniques used on the old tattoo and the skill of the tattoo artist.
Covering up a previous tattoo necessitates darker tones in the new tattoo to effectively hide the older, unwanted piece.
Many tattoos are too dark to cover up and in those cases patients may receive laser tattoo removal to lighten the existing ink to make themselves better candidates for a cover up tattoo.

\subsection{Laser removal}
Tattoo removal is most commonly performed using lasers that break down the ink particles in the tattoo into smaller particles.
In the case of tattoo pigments, macrophages collect ink pigments, but have difficulty breaking them down.
A tattoo laser must be capable of emitting adequate energy within the given absorption spectrum of the pigment to provide an effective treatment.
Certain tattoo pigments, such as yellows and fluorescent inks are more challenging to treat than darker blacks and blues, because they have absorption spectra that fall outside or on the edge of the emission spectra available in the tattoo removal laser.
The gold standard of tattoo removal treatment modality is considered to be laser tattoo removal using multiple separate Q-switched lasers over a number of repeat visits.
Lasers developed during or after 2006 provide multiple wavelengths and can successfully treat a much broader range of tattoo pigments than previous individual Q-switched lasers.
During the treatment process, the laser beam passes through the skin, targeting the ink resting in a liquid state within.

\subsubsection{Mechanism of laser action}
In 1978 a carbon dioxide laser was also used, but because it targeted water, a chromophore present in all cells, this type of laser generally caused scarring after treatments.

One of the first American published articles describing laser tattoo removal was authored by a group at Massachusetts General Hospital in 1990.

Laser treatment causes tattoo pigment particles to heat up and fragment into smaller pieces.

For laser tattoo removal the selective destruction of tattoo pigments depends on four factors: The color of the light must penetrate sufficiently deep into the skin to reach the tattoo pigment.

The color of the laser light must be more highly absorbed by the tattoo pigment than the surrounding skin.

The time duration of the laser energy must be very short, so that the tattoo pigment is heated to fragmentation temperature before its heat can dissipate to the surrounding skin.

A novel method for laser tattoo removal using a fractionated CO2 or Erbium:YAG laser, alone or in combination with Q-switched lasers, was reported by Ibrahimi and coworkers from the Wellman Center of Photomedicine at the Massachusetts General Hospital in 2011.

\subsubsection{Laser parameters that affect results}
Several colors of laser light are used for tattoo removal, from visible light to near-infrared radiation.

Multi-color tattoo removal almost always requires the use of two or more laser wavelengths.

Tattoo removal lasers are usually identified by the lasing medium used to create the wavelength which makes the laser wavelength effective for age spot or sun spot removal.

The weakest of all the q-switched devices and somewhat similar to the Ruby laser in that the Alexandrite creates a red light which is highly absorbed by green and dark tattoo pigments.

The alexandrite laser color is slightly less absorbed by melanin, so this laser has a slightly lower incidence of unwanted pigmentary changes than a ruby laser.

Dye modules are available for some lasers to convert 532 nm to 650 nm or 585 nm light which allows one laser system to safely and effectively treat multi-color tattoo inks.

Larger spot sizes slightly increase the effective penetration depth of the laser light, thus enabling more effective targeting of deeper tattoo pigments.

\subsubsection{Number of laser tattoo removal treatment sessions needed}
The number of treatments necessary to remove a tattoo via laser can be predicted by the Kirby-Desai Scale.

Complete laser tattoo removal requires numerous treatment sessions, typically spaced at eight weeks or more apart.

Patients should inquire about the laser being used if the R20 treatment method is offered by a facility as it is usually only offered by clinics that are using the 755 nm Alexandrite as opposed to the more powerful and versatile devices that are more commonly used.

Multiple pass treatment methods have generally shown to carry a greater risk of side effects, due to the increased amount of energy used in treatment.

A PFD patch utilizes a clear silicone gel patch, with a small amount of PFD liquid applied to the treatment area immediately before each pass of laser application, and conducting the passes in rapid succession.

The combination of the patch and liquid reduce the epidermal scatter, which can limit the predicted side effects typically seen in aggressive laser tattoo removal treatments.

All these physical properties of the patch work to substantially reduce the total number of laser treatments required for ink clearance.
\subsubsection{Factors contributing to the success of laser tattoo removal}
There are a number of factors that determine how many treatments will be needed and the level of success one might experience.

Age of tattoo, ink density, color and even where the tattoo is located on the body, and whether the tattoo was professional, or not, all play an important role in how many treatments will be needed for complete removal.

A rarely recognized factor of tattoo removal is the role of the client's immune response.

The normal process of tattoo removal is fragmentation followed by phagocytosis which is then drained away via the lymphatics.

It is the inflammation resulting from the actual laser treatment and the natural stimulation of the hosts' immune response that ultimately results in removal of tattoo ink; thus variations in results are enormous.
\subsubsection{Pain management during treatment}
Laser tattoo removal is painful; many patients say it is worse than getting the tattoo.
The pain is often described to be similar to that of hot oil on the skin, or a "Snap" from an elastic band.
Depending on the patient's pain threshold, and while some patients may forgo anesthesia altogether, most patients will require some form of local anesthesia.
A better method is complete anesthesia which can be administered locally by injections of 1\% to 2\% lidocaine with epinephrine.
A technique which helps to reduce the pain sensation felt by patients has been described by MJ Murphy.
He used a standard microscope glass slide pressed against the tattooed skin and fired the laser through the glass.
This technique may represent a simplest and effective method to reduce the pain sensation when treating small tattoos.

\subsubsection{Post-treatment considerations
}Immediately after laser treatment, a slightly elevated, white discoloration with or without the presence of punctuate bleeding is often observed.
Pinpoint bleeding represents vascular injury from photoacoustic waves created by the laser's interaction with tattoo pigment.
Minimal edema and erythema of adjacent normal skin usually resolve within 24 hours.
Subsequently, a crust appears over the entire tattoo, which sloughs off at approximately two weeks post-treatment.
As noted above, some tattoo pigment may be found within this crust.
Post-operative wound care consists of simple wound care and a non-occlusive dressing.
Fading of the tattoo will be noted over the next eight weeks and re-treatment energy levels can be tailored depending on the clinical response observed.


\subsection{Side effects and complications}
About half of the patients treated with Q-switched lasers for tattoo removal will show some transient changes in the normal skin pigmentation.
Local allergic responses to many tattoo pigments have been reported, and allergic reactions to tattoo pigment after Q-switched laser treatment are also possible.
Studies of various tattoo pigments have shown that a number of pigments change color when irradiated with Q-switched laser energy.
Some tattoo colors including flesh tones, light red, white, peach and light brown containing pigments as well as some green and blue tattoo pigments, changed to black when irradiated with Q-switched laser pulses.
If tattoo darkening does occur, after 8 weeks the newly darkened tattoo can be treated as if it were black pigment.
Very rarely, non Q-switched laser treatments, like CO2 or Argon lasers, which are very rarely offered these days, can rupture blood vessels and aerosolize tissue requiring a plastic shield or a cone device to protect the laser operator from tissue and blood contact.
While the infrequent bulla development is a possible side effect of Q-switched laser tattoo removal, if treated appropriately and quickly by the health care practitioner, it is unlikely that long term consequences would ensue.


\subsubsection{Risks}
Although laser treatment is well known and often used to remove tattoos, unwanted side effects of laser tattoo removal include the possibility of discoloration of the skin such as hypopigmentation and hyperpigmentation as well as textural changes - these changes are usually not permanent when the Nd:YAG is used but it is much more likely with the use of the 755 nm Alexandrite, the 694 nm Ruby and the R20 method.
Occasionally, "Paradoxical darkening" of a tattoo may occur, when a treated tattoo becomes darker instead of lighter.
This occurs most often with white ink, flesh tones, pink, and cosmetic make-up tattoos.
Some tattoo pigments contain metals that could theoretically break down into toxic chemicals in the body when exposed to light.
This has not yet been reported in vivo but has been shown in laboratory tests.
Laser removal of traumatic tattoos may similarly be complicated depending on the substance of the pigmenting material.
In one reported instance, the use of a laser resulted in the ignition of embedded particles of firework debris.



\end{document}